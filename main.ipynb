{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00eb1c2",
   "metadata": {},
   "source": [
    "<b style='Color:red'> The python version used for running this notebook is 3.11.8 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import cv2, math\n",
    "from skimage import morphology,filters, util\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dd5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please replace it with the correct file path on your computer\n",
    "filePath = \"C:/Users/user/Documents/BHE/BRUNNER/data_v3/SCORPIO_LWIR/\"\n",
    "filePath = \"C:/Users/user/Documents/BHE/BRUNNER/data_v1/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60218262",
   "metadata": {},
   "source": [
    "# Create a directory for saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf48c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory for plots\n",
    "if not(os.path.isdir(\"./results\")):\n",
    "    os.mkdir(\"./results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c69fe",
   "metadata": {},
   "source": [
    "# Gaussian Filtration with Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81451297",
   "metadata": {},
   "source": [
    "What we need to do next is to find a way to classify columns chronologically. I had some ideas but still need some fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca01f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"REF_N5.h5\"\n",
    "file = h5.File(\"{}{}\".format(filePath,filename), 'r')\n",
    "df_total = pd.DataFrame()\n",
    "testImages = file.keys()\n",
    "T1 = 7 #We deduced this value experimentally (tested on different data samples).\n",
    "for k in testImages:\n",
    "    imagename = k\n",
    "    image1 = file[imagename]\n",
    "    image1 = file[imagename][:image1.shape[1]]\n",
    "\n",
    "    image_uint8 = util.img_as_ubyte(image1 / np.max(image1))\n",
    "    footprint = morphology.footprint_rectangle((30, 1))\n",
    "    # filter using mean bilateral method\n",
    "    filtered = filters.rank.mean_bilateral(image_uint8, footprint, s0=10, s1=10)\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, thresholded = cv2.threshold(filtered, 125, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C)  # in some dataset, we needed to lower the min value to 60 instead of 125\n",
    "    #if the image has white background with black noise after cleaning, inverse it\n",
    "    if np.mean(thresholded) > 200:\n",
    "        thresholded = abs(255 - thresholded)\n",
    "    window_height = 30\n",
    "    h, w = thresholded.shape\n",
    "\n",
    "    # Normalize thresholded image to binary (0 or 1)\n",
    "    binary = (thresholded > 0).astype(np.uint8)\n",
    "    binary2 = (thresholded>0)\n",
    "    num_windows = math.ceil(h / window_height)\n",
    "    column_window_sums = np.zeros((num_windows, w), dtype=np.uint16)\n",
    "\n",
    "    for win in range(num_windows):\n",
    "        start_row = win * window_height\n",
    "        end_row = start_row + window_height\n",
    "        window_slice = binary[start_row:end_row, :]\n",
    "        column_window_sums[win,:] = window_slice.sum(axis=0)\n",
    "    column_window_sums[column_window_sums<T1] = 0\n",
    "\n",
    "    defect_columns = np.where(column_window_sums >= T1)[1]\n",
    "    affected_windows_per_column = {}\n",
    "    for col in defect_columns:\n",
    "        count = np.count_nonzero(column_window_sums[:, col])\n",
    "        #if the column has only 1 window with lowe value, remove it\n",
    "        if count == 1 and column_window_sums[:, col].sum() <13:\n",
    "            column_window_sums[:, col] = 0\n",
    "        else:\n",
    "            lbl = int(col)\n",
    "            affected_windows_per_column[lbl] = count\n",
    "    #if the frame has any detected faulty column, create plots and append the columns to data frame\n",
    "    if affected_windows_per_column:\n",
    "        fig,ax=plt.subplots(2,2,figsize=(16, 9))\n",
    "\n",
    "        ax[0][0].set_title(\"Original Image\")\n",
    "        ax[0][0].imshow(image_uint8,cmap='gray')\n",
    "        fig.suptitle(\"Local Dark Pixel Density {}\".format(k))\n",
    "        ax[0][1].imshow(thresholded,cmap='gray')\n",
    "        ax[0][1].set_title(\"Thresholded and smoothed Image\")\n",
    "        # if affected_windows_per_column:\n",
    "        plt1=ax[1][0].imshow(column_window_sums, cmap='hot', aspect='auto')\n",
    "        cbar = fig.colorbar(plt1, ax=ax[1][0])\n",
    "        cbar.set_label(\"White Spot Count in 30-px Window\")\n",
    "        ax[1][0].set_title(\"Column HeatMap\")\n",
    "        fig.delaxes(ax[1][1])\n",
    "        fig.savefig('./results/{}.png'.format(k))\n",
    "        plt.close()\n",
    "        data_dict = {}\n",
    "        for col in affected_windows_per_column.keys():\n",
    "            data_dict[col] = column_window_sums[:, col]\n",
    "\n",
    "        # Create DataFrame from dict\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        df['window'] = df.index  # Add window index for x-axis\n",
    "\n",
    "        # Melt for grouped bar chart\n",
    "        df_melted = df.melt(id_vars='window', var_name='column', value_name='value')\n",
    "        df_melted['frame'] = k\n",
    "        df_melted['windows_total'] = num_windows\n",
    "        df_total = pd.concat([df_total,df_melted])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6951d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_analysis = {\"frame\":[],'column':[],'windows':[],\"values_mean\":[],\"values_sd\":[],\"type\":[],\"start\":[],\"end\":[]}\n",
    "#types can be F:fractioned, C:complete,\n",
    "df_c = df_total.copy()\n",
    "df_c = df_c[df_c['value'] >0]\n",
    "frames = list(df_c['frame'].unique())\n",
    "for frame in frames:\n",
    "    df_f = df_c.copy()\n",
    "    df_f = df_f[df_f['frame'] == frame]\n",
    "    columns = list(df_f['column'].unique())\n",
    "    type = \"\"\n",
    "    for column in columns:\n",
    "        df_col = df_f.copy()\n",
    "        df_col = df_col[df_col['column'] == column]\n",
    "        nb_windows = df_f.shape[0]\n",
    "        if nb_windows == 1:\n",
    "            min_index = df_col['window'].iloc[0]\n",
    "            max_index = min_index\n",
    "            type = \"Partial\"\n",
    "        else:\n",
    "            min_index = df_col['window'].min()\n",
    "            max_index = df_col['window'].max()\n",
    "            total_windows = df_col['windows_total'].iloc[0]\n",
    "            if (max_index - min_index)/total_windows >=0.7:\n",
    "                type = 'Complete'\n",
    "            else:\n",
    "                type = 'Partial'\n",
    "    dict_analysis['frame'].append(frame)\n",
    "    dict_analysis['column'].append(column)\n",
    "    dict_analysis['windows'].append(nb_windows)\n",
    "    dict_analysis['values_mean'].append(df_col['value'].mean())\n",
    "    dict_analysis['values_sd'].append(df_col['value'].std())\n",
    "    dict_analysis['start'].append(min_index)\n",
    "    dict_analysis['end'].append(max_index)\n",
    "    dict_analysis['type'].append(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00369ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame(dict_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219dc44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_37456\\1940942491.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_analysis = df_analysis.groupby(\"column\", group_keys=False).apply(assign_groups)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_37456\\1940942491.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_analysis = df_analysis.groupby([\"column\", \"chunk\"], group_keys=False).apply(label_status)\n"
     ]
    }
   ],
   "source": [
    "df_analysis['frame'] = df_analysis['frame'].apply(lambda x: int(x.replace(\"Image \",\"\")))\n",
    "df_analysis = df_analysis.sort_values(['column','frame']).reset_index(drop=True)\n",
    "cnstColThreshold = 3\n",
    "def assign_groups(group):\n",
    "    group = group.copy()\n",
    "    group[\"frame_diff\"] = group[\"frame\"].diff().fillna(1)\n",
    "    group[\"chunk\"] = (group[\"frame_diff\"] > 1).cumsum()\n",
    "    return group\n",
    "\n",
    "df_analysis = df_analysis.groupby(\"column\", group_keys=False).apply(assign_groups)\n",
    "#if the same column is noisy in more that 2 consecutive frames, it is constant\n",
    "def label_status(subgroup):\n",
    "    frames = subgroup[\"frame\"].values\n",
    "    status = \"temporal\"\n",
    "    for i in range(len(frames) - 2):\n",
    "        if frames[i+1] == frames[i] + 1 and frames[i+2] == frames[i] + 2:\n",
    "            status = \"constant\"\n",
    "            break\n",
    "    subgroup[\"status\"] = status\n",
    "    return subgroup\n",
    "\n",
    "df_analysis = df_analysis.groupby([\"column\", \"chunk\"], group_keys=False).apply(label_status)\n",
    "df_analysis = df_analysis.drop(columns=[\"frame_diff\"])\n",
    "df_analysis = df_analysis.drop(columns=[\"chunk\"])\n",
    "df_analysis.to_csv(\"./results/{}.csv\".format(filename.replace(\".h5\",\"\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
